{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case Folding"
      ],
      "metadata": {
        "id": "GuloN0kF0TWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7rpUPnV0Lml",
        "outputId": "81de8d8b-80c3-47d0-9b62-c0f6b71769f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\n",
            "Teks setelah diubah menjadi lowercase: ini adalah contoh teks yang akan dikonversi menjadi lowercase.\n"
          ]
        }
      ],
      "source": [
        "# Contoh teks\n",
        "teks_asli = \"Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\"\n",
        "\n",
        "# Mengubah teks menjadi lowercase\n",
        "teks_lowercase = teks_asli.lower()\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah diubah menjadi lowercase:\", teks_lowercase)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh teks dengan campuran huruf besar dan kecil\n",
        "teks_asli = \"\"\"\n",
        "Ini adalah contoh teks dengan campuran huruf besar dan kecil.\n",
        "Contoh ini digunakan untuk demonstrasi case folding dalam pra-pemrosesan teks.\n",
        "Dengan menggunakan case folding, semua huruf dalam teks akan diubah menjadi huruf kecil.\n",
        "Ini membantu dalam memastikan konsistensi dalam analisis teks.\n",
        "\"\"\"\n",
        "\n",
        "# Mengubah teks menjadi lowercase menggunakan case folding\n",
        "teks_case_folded = teks_asli.lower()\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\")\n",
        "print(teks_asli)\n",
        "print(\"Teks setelah case folding:\")\n",
        "print(teks_case_folded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-5lrlZF0glo",
        "outputId": "a9b7e6ff-546f-4cdd-d8ea-495ff134ad7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli:\n",
            "\n",
            "Ini adalah contoh teks dengan campuran huruf besar dan kecil.\n",
            "Contoh ini digunakan untuk demonstrasi case folding dalam pra-pemrosesan teks.\n",
            "Dengan menggunakan case folding, semua huruf dalam teks akan diubah menjadi huruf kecil.\n",
            "Ini membantu dalam memastikan konsistensi dalam analisis teks.\n",
            "\n",
            "Teks setelah case folding:\n",
            "\n",
            "ini adalah contoh teks dengan campuran huruf besar dan kecil.\n",
            "contoh ini digunakan untuk demonstrasi case folding dalam pra-pemrosesan teks.\n",
            "dengan menggunakan case folding, semua huruf dalam teks akan diubah menjadi huruf kecil.\n",
            "ini membantu dalam memastikan konsistensi dalam analisis teks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removal Special Characters"
      ],
      "metadata": {
        "id": "4gghEsOP0fc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menghapus Angka"
      ],
      "metadata": {
        "id": "fZqoKSE-1ZlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghapus angka dari teks\n",
        "def hapus_angka(teks):\n",
        "    teks_tanpa_angka = ''.join([char for char in teks if not char.isdigit()])\n",
        "    return teks_tanpa_angka\n",
        "\n",
        "# Contoh teks dengan angka\n",
        "teks_dengan_angka = \"Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka\n",
        "teks_tanpa_angka = hapus_angka(teks_dengan_angka)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks dengan angka:\", teks_dengan_angka)\n",
        "print(\"Teks tanpa angka:\", teks_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVknOhfI1Rrv",
        "outputId": "cca0285b-d268-4238-b266-3161064e8cac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks dengan angka: Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\n",
            "Teks tanpa angka: Ini adalah contoh teks dengan angka  yang akan dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menghapus Tanda Baca"
      ],
      "metadata": {
        "id": "yvg48Uo61dpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Membuat set yang berisi semua tanda baca\n",
        "    punctuation_set = set(string.punctuation)\n",
        "\n",
        "    # Menghapus tanda baca dari teks\n",
        "    text_without_punctuation = ''.join(char for char in text if char not in punctuation_set)\n",
        "\n",
        "    return text_without_punctuation\n",
        "\n",
        "# Contoh teks dengan banyak tanda baca\n",
        "teks_asli = \"\"\"\n",
        "Dalam dunia ini, banyak hal terjadi, dari yang kecil hingga yang besar. Kita bisa melihat keindahan, tapi juga kekejaman. Ada harapan, namun juga keputusasaan. Bagaimanapun, hidup terus berjalan, tak peduli apa pun yang terjadi!\n",
        "\"\"\"\n",
        "\n",
        "# Menghapus tanda baca dari teks\n",
        "teks_tanpa_tanda_baca = remove_punctuation(teks_asli)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\")\n",
        "print(teks_asli)\n",
        "print(\"\\nTeks setelah menghapus tanda baca:\")\n",
        "print(teks_tanpa_tanda_baca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9oT05o700Ip",
        "outputId": "bcff1429-6310-410e-9872-da856348f0d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli:\n",
            "\n",
            "Dalam dunia ini, banyak hal terjadi, dari yang kecil hingga yang besar. Kita bisa melihat keindahan, tapi juga kekejaman. Ada harapan, namun juga keputusasaan. Bagaimanapun, hidup terus berjalan, tak peduli apa pun yang terjadi!\n",
            "\n",
            "\n",
            "Teks setelah menghapus tanda baca:\n",
            "\n",
            "Dalam dunia ini banyak hal terjadi dari yang kecil hingga yang besar Kita bisa melihat keindahan tapi juga kekejaman Ada harapan namun juga keputusasaan Bagaimanapun hidup terus berjalan tak peduli apa pun yang terjadi\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menghilangkan Whitespace"
      ],
      "metadata": {
        "id": "zc4UCYpI1hk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teks = \"   Ini adalah contoh kalimat dengan spasi di awal dan akhir.    \"\n",
        "teks_setelah_strip = teks.strip()\n",
        "print(teks_setelah_strip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kiYK9vL03OW",
        "outputId": "d53c6445-5978-41c8-ce87-980372335d2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ini adalah contoh kalimat dengan spasi di awal dan akhir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords Removal"
      ],
      "metadata": {
        "id": "n7gnNsUZ1nZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download korpus stopwords bahasa Indonesia dari NLTK jika belum terunduh\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')  # Untuk tokenisasi kata\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Ambil daftar stopwords bahasa Indonesia dari NLTK\n",
        "stopwords_indonesia = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_indonesia]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords NLTK:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKXHYYM21uDe",
        "outputId": "d0e2c4a2-d3e4-4a65-89e7-8e7c5e807441"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords NLTK: Perekonomian Indonesia pertumbuhan membanggakan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing"
      ],
      "metadata": {
        "id": "F8Q4twFo2RGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word tokenizing"
      ],
      "metadata": {
        "id": "J-XBJM1d2anz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalkan kita ingin memisahkan frasa berdasarkan tanda baca koma (,)\n",
        "text = \"Ini adalah contoh kalimat untuk tokenisasi kata\"\n",
        "phrases = text.split(' ')\n",
        "print(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrAFF7AV2SDJ",
        "outputId": "8b72e4c6-cad3-43f9-dddf-f5fca432b0c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'kalimat', 'untuk', 'tokenisasi', 'kata']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Tokenizing"
      ],
      "metadata": {
        "id": "zYiSHCPM2uLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh aturan tokenisasi khusus untuk tokenisasi kata dalam bahasa Indonesia\n",
        "import re\n",
        "\n",
        "text = \"Ini adalah contoh kalimat pertama. Dan ini adalah contoh kalimat kedua.\"\n",
        "sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAwqFV_72yGr",
        "outputId": "e6df6776-941c-455a-fcab-9b3d7340f54a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini adalah contoh kalimat pertama.', 'Dan ini adalah contoh kalimat kedua.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phrase Tokenizing"
      ],
      "metadata": {
        "id": "BbZ2ar9G2-Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalkan kita ingin memisahkan frasa berdasarkan tanda baca koma (,)\n",
        "text = \"Apel, jeruk, pisang, dan mangga.\"\n",
        "phrases = text.split(',')\n",
        "print(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlQ-4xXP29Y0",
        "outputId": "36959c84-0af7-4b70-d624-da7ac465ee7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apel', ' jeruk', ' pisang', ' dan mangga.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-based Tokenizing"
      ],
      "metadata": {
        "id": "RzW1sI5W3Ik3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh aturan tokenisasi khusus untuk tokenisasi kata dalam bahasa Indonesia\n",
        "import re\n",
        "\n",
        "text = \"Pertama, kita perlu menyiapkan bahan-bahan yang diperlukan.\"\n",
        "tokens = re.findall(r'\\w+|\\d+', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLyUXAPK3KwK",
        "outputId": "efde21a6-7ca0-4420-8f70-52879ab6173c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pertama', 'kita', 'perlu', 'menyiapkan', 'bahan', 'bahan', 'yang', 'diperlukan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model-based Tokenizing"
      ],
      "metadata": {
        "id": "uZMMN4Hq3U63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalnya menggunakan spasi sebagai pemisah kata\n",
        "text = \"Ini adalah contoh tokenisasi berbasis model.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnOFneYD3UAw",
        "outputId": "634c327c-7a0b-4778-8e1e-e63e9eced8fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'berbasis', 'model.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "Yj79nLS73ony"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "words = [\"running\", \"easily\", \"bought\", \"crying\", \"leaves\"]\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEAvrteU3uJX",
        "outputId": "d7dc2217-0ce1-4bc9-901a-94903f3860aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'easili', 'bought', 'cri', 'leav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "uBMdRT0b31wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"easily\", \"bought\", \"crying\", \"leaves\"]\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in words]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHeXE5Nc344x",
        "outputId": "1ccc3d06-553b-4fa6-de27-15dbf31ee029"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'easily', 'buy', 'cry', 'leave']\n"
          ]
        }
      ]
    }
  ]
}